{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7KBOS0yO_mi"
      },
      "source": [
        "# LAB | Abstractive Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL4goh8fPC5l"
      },
      "source": [
        "Abstractive question-answering focuses on the generation of multi-sentence answers to open-ended questions. It usually works by searching massive document stores for relevant information and then using this information to synthetically generate answers. This notebook demonstrates how Pinecone helps you build an abstractive question-answering system. We need three main components:\n",
        "\n",
        "- A vector index to store and run semantic search\n",
        "- A retriever model for embedding context passages\n",
        "- A generator model to generate answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6uNNJmuPIVT"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-core langchain-classic langchain-pinecone langchain-huggingface datasets pinecone-client sentence-transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or_0JbG_Bxwr",
        "outputId": "763b0a91-bd4f-4d50-db7c-e589e0f5f94c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.16)\n",
            "Requirement already satisfied: langchain-classic in /usr/local/lib/python3.12/dist-packages (1.0.1)\n",
            "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.12/dist-packages (0.2.13)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (2.18.0)\n",
            "Collecting datasets\n",
            "  Using cached datasets-4.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting pinecone-client\n",
            "  Using cached pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.10.0+cu128)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.7.3)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (1.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.32.4)\n",
            "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic) (2.0.46)\n",
            "Collecting pinecone<8.0.0,>=6.0.0 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
            "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy!=2.0.2,>=1.26.4 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (1.26.4)\n",
            "Requirement already satisfied: langchain-openai>=0.3.11 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (1.1.10)\n",
            "Requirement already satisfied: httpx>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (0.28.1)\n",
            "Requirement already satisfied: simsimd>=5.9.11 in /usr/local/lib/python3.12/dist-packages (from langchain-pinecone) (6.5.13)\n",
            "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain-huggingface)\n",
            "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain-huggingface) (0.22.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.24.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Using cached pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (3.0.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2026.2.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.12/dist-packages (from pinecone-client) (2026.1.4)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from pinecone-client) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from pinecone-client) (2.5.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: cuda-bindings==12.9.4 in /usr/local/lib/python3.12/dist-packages (from torch) (12.9.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.6.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.0)\n",
            "Requirement already satisfied: cuda-pathfinder~=1.1 in /usr/local/lib/python3.12/dist-packages (from cuda-bindings==12.9.4->torch) (1.3.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.0->langchain-pinecone) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.0->langchain-pinecone) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.3.11->langchain-pinecone) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai>=0.3.11->langchain-pinecone) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
            "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone)\n",
            "  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->langchain-classic) (3.4.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3.0.0,>=1.4.0->langchain-classic) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Using cached transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
            "  Using cached transformers-5.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "  Using cached transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.3.11->langchain-pinecone) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.3.11->langchain-pinecone) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai>=0.3.11->langchain-pinecone) (1.3.1)\n",
            "Using cached datasets-4.6.0-py3-none-any.whl (520 kB)\n",
            "Using cached pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
            "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
            "Using cached pyarrow-23.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (47.6 MB)\n",
            "Using cached transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
            "Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
            "Installing collected packages: pyarrow, pinecone-plugin-assistant, pinecone-client, huggingface-hub, pinecone, transformers, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: pinecone-plugin-assistant\n",
            "    Found existing installation: pinecone-plugin-assistant 3.0.2\n",
            "    Uninstalling pinecone-plugin-assistant-3.0.2:\n",
            "      Successfully uninstalled pinecone-plugin-assistant-3.0.2\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.1\n",
            "    Uninstalling huggingface_hub-1.4.1:\n",
            "      Successfully uninstalled huggingface_hub-1.4.1\n",
            "  Attempting uninstall: pinecone\n",
            "    Found existing installation: pinecone 8.1.0\n",
            "    Uninstalling pinecone-8.1.0:\n",
            "      Successfully uninstalled pinecone-8.1.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.2.0\n",
            "    Uninstalling transformers-5.2.0:\n",
            "      Successfully uninstalled transformers-5.2.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.18.0\n",
            "    Uninstalling datasets-2.18.0:\n",
            "      Successfully uninstalled datasets-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.50.0 requires pandas<3.0,>=1.0, but you have pandas 3.0.1 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "db-dtypes 1.5.0 requires pandas<3.0.0,>=1.5.3, but you have pandas 3.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-4.6.0 huggingface-hub-0.36.2 pinecone-7.3.0 pinecone-client-6.0.0 pinecone-plugin-assistant-1.8.0 pyarrow-23.0.1 transformers-4.57.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y pyarrow datasets numpy pandas transformers sentence-transformers huggingface_hub -q\n",
        "!pip install numpy==1.26.4 \"pyarrow==14.0.2\" \"datasets==2.18.0\" transformers sentence-transformers huggingface_hub -U -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyypuNV1CpNe",
        "outputId": "bafcc57b-929b-4160-8807-b8e1199679f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-huggingface 1.2.0 requires huggingface-hub<1.0.0,>=0.33.4, but you have huggingface-hub 1.4.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 3.0.1 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "dask-cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "tensorflow 2.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.5 which is incompatible.\n",
            "gradio 5.50.0 requires pandas<3.0,>=1.0, but you have pandas 3.0.1 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires pandas<2.4.0dev0,>=2.0, but you have pandas 3.0.1 which is incompatible.\n",
            "cudf-cu12 25.10.0 requires pyarrow>=15.0.0; platform_machine == \"x86_64\", but you have pyarrow 14.0.2 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "bigframes 2.35.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "bqplot 0.12.45 requires pandas<3.0.0,>=1.0.0, but you have pandas 3.0.1 which is incompatible.\n",
            "db-dtypes 1.5.0 requires pandas<3.0.0,>=1.5.3, but you have pandas 3.0.1 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0EU4eIbPTTL"
      },
      "source": [
        "# Load and Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USvwSnsDvrdz"
      },
      "source": [
        "Our source data will be taken from the Wiki Snippets dataset, which contains over 17 million passages from Wikipedia. But, since indexing the entire dataset may take some time, we will only utilize 50,000 passages in this demo that include \"History\" in the \"section title\" column. If you want, you may utilize the complete dataset. Pinecone vector database can effortlessly manage millions of documents for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bShG-f5IPPtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cf5fda5-083e-4f26-c022-c98ba568ce8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/datasets/load.py:1461: FutureWarning: The repository for vblagoje/wikipedia_snippets_streamed contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/vblagoje/wikipedia_snippets_streamed\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the dataset from huggingface in streaming mode and shuffle it\n",
        "from datasets import load_dataset\n",
        "wiki_data = load_dataset(\n",
        "    'vblagoje/wikipedia_snippets_streamed',\n",
        "    split='train',\n",
        "    streaming=True\n",
        ").shuffle(seed=960)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoPdaLFAvvci"
      },
      "source": [
        "We are loading the dataset in the streaming mode so that we don't have to wait for the whole dataset to download (which is over 9GB). Instead, we iteratively download records one at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLjXCwKevy4K",
        "outputId": "56e7f955-f7ad-446c-e517-1b8b77da6d18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'wiki_id': 'Q7649565',\n",
              " 'start_paragraph': 20,\n",
              " 'start_character': 272,\n",
              " 'end_paragraph': 24,\n",
              " 'end_character': 380,\n",
              " 'article_title': 'Sustainable Agriculture Research and Education',\n",
              " 'section_title': \"2000s & Evaluation of the program's effectiveness\",\n",
              " 'passage_text': \"preserving the surrounding prairies. It ran until March 31, 2001.\\nIn 2008, SARE celebrated its 20th anniversary. To that date, the program had funded 3,700 projects and was operating with an annual budget of approximately $19 million. Evaluation of the program's effectiveness As of 2008, 64% of farmers who had received SARE grants stated that they had been able to earn increased profits as a result of the funding they received and utilization of sustainable agriculture methods. Additionally, 79% of grantees said that they had experienced a significant improvement in soil quality though the environmentally friendly, sustainable methods that they were\"}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# show the contents of a single document in the dataset\n",
        "next(iter(wiki_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yHYNM6VXv1MJ"
      },
      "outputs": [],
      "source": [
        "# The 'wiki_snippets' dataset does not have 'section_title', so we will proceed without this specific filter\n",
        "history = wiki_data.filter(lambda x: x[\"section_title\"] == \"History\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8sTBqS0v4RM"
      },
      "source": [
        "Let's iterate through the dataset and apply our filter to select the 50,000 historical passages. We will extract `article_title`, `section_title` and `passage_text` from each document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "84165d4c9b0d4870ab75f94fdd2988b4",
            "a45906e001b14c838c79e09388f4b354",
            "797f94464acc469ea68c9d3522554986",
            "deee5e26f38c459d8dcf26169d5fa133",
            "55c9bee27d1b4581ab39016825ce7445",
            "c24ac69baa134755a70a18084bf97f10",
            "bce6c37c882f41fbb557f4244b33f0cf",
            "d48fb4902c7a42b08519b856aa12acf4",
            "8a2d0e72ddbb417f866ad40017f35953",
            "ec08e63ee75c4fd99e110ab7df43425b",
            "5f5bc42fe47f4dc782f3a26f42f19c53"
          ]
        },
        "id": "Ob0prowIzjJ9",
        "outputId": "4a8d52f9-6c1d-4903-9ed3-90f54d45bd5d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84165d4c9b0d4870ab75f94fdd2988b4"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.auto import tqdm  # progress bar\n",
        "\n",
        "total_doc_count = 10000\n",
        "\n",
        "counter = 0\n",
        "docs = []\n",
        "# iterate through the dataset and apply our filter\n",
        "for d in tqdm(history, total=total_doc_count):\n",
        "    # extract the fields we need - article, section, and passage\n",
        "    article_title = d['article_title']\n",
        "    passage_text = d['passage_text']\n",
        "    section_title = \"\" # 'wiki_snippets' does not have a section_title field\n",
        "\n",
        "    # Only collect up to total_doc_count documents\n",
        "    if counter < total_doc_count:\n",
        "        docs.append({\n",
        "            'article_title': article_title,\n",
        "            'section_title': section_title,\n",
        "            'passage_text': passage_text\n",
        "        })\n",
        "        counter += 1\n",
        "    else:\n",
        "        break # Stop after reaching the desired number of documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RvTA40mq5FKj",
        "outputId": "4433f4b5-6f68-4c69-af04-65be17713aa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              article_title section_title  \\\n",
              "0                            Taupo District                 \n",
              "1  The Bishop Wand Church of England School                 \n",
              "2               Surface Hill Uniting Church                 \n",
              "3                       The Electras (band)                 \n",
              "4                             Swanton House                 \n",
              "\n",
              "                                        passage_text  \n",
              "0  was not until the 1950s that the region starte...  \n",
              "1  The Bishop Wand Church of England School Histo...  \n",
              "2  in perpetual reminder that work and worship go...  \n",
              "3  as its B-side. However, copies of the single, ...  \n",
              "4  it. Lane provided funds for restoration by the...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_title</th>\n",
              "      <th>section_title</th>\n",
              "      <th>passage_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Taupo District</td>\n",
              "      <td></td>\n",
              "      <td>was not until the 1950s that the region starte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Bishop Wand Church of England School</td>\n",
              "      <td></td>\n",
              "      <td>The Bishop Wand Church of England School Histo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Surface Hill Uniting Church</td>\n",
              "      <td></td>\n",
              "      <td>in perpetual reminder that work and worship go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Electras (band)</td>\n",
              "      <td></td>\n",
              "      <td>as its B-side. However, copies of the single, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Swanton House</td>\n",
              "      <td></td>\n",
              "      <td>it. Lane provided funds for restoration by the...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# create a pandas dataframe with the documents we extracted\n",
        "df = pd.DataFrame(docs)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDYP3RkcPYdf"
      },
      "source": [
        "# Initialize Pinecone Index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5m5HHVu4War"
      },
      "source": [
        "The Pinecone index stores vector representations of our historical passages which we can retrieve later using another vector (query vector). To build our vector index, we must first establish a connection with Pinecone. For this, we need an API from Pinecone. You can get one for free from [here](https://app.pinecone.io/), and after that, we initialize the connection as follows:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y pinecone-client pinecone -q\n",
        "!pip install \"pinecone[grpc]\" -U -q  # Latest v5 with gRPC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHOLfFGjEpq3",
        "outputId": "c6c527e8-a872-4e04-9dbf-af224f727eed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-pinecone 0.2.13 requires pinecone[asyncio]<8.0.0,>=6.0.0, but you have pinecone 8.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "def get_pinecone_api_key():\n",
        "    \"\"\"Retrieves the Pinecone API key from Colab secrets.\"\"\"\n",
        "    # Ensure the secret is named 'PINECONE_API_KEY' in Colab secrets\n",
        "    return userdata.get('PINECONE_API_KEY')\n",
        "\n",
        "# Example usage:\n",
        "pinecone_api_key = get_pinecone_api_key()\n"
      ],
      "metadata": {
        "id": "aP05UMvJtAnO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from pinecone import Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-east-1\"\n",
        ")\n",
        "\n",
        "# connect to pinecone environment\n",
        "pc = Pinecone(api_key=pinecone_api_key, environment=spec.region)"
      ],
      "metadata": {
        "id": "2TAi-GtMIEyk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKxCqwjRo6tj"
      },
      "source": [
        "Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPJmTIy4XsL"
      },
      "source": [
        "Now we create a new index. We will name it \"abstractive-question-answering\" — you can name it anything we want. We specify the metric type as \"cosine\" and dimension as 768 because the retriever we use to generate context embeddings is optimized for cosine similarity and outputs 768-dimension vectors."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"abstractive-question-answering\"\n",
        "\n",
        "# Check if index exists & create with ServerlessSpec\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")  # ✅ REQUIRED for serverless\n",
        "    )\n",
        "\n",
        "# Connect to index\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "1g4l7mAAKUUk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHcCQVi4PcmE"
      },
      "source": [
        "# Initialize Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udmF-qY24yQ1"
      },
      "source": [
        "Next, we need to initialize our retriever. The retriever will mainly do two things:\n",
        "\n",
        "- Generate embeddings for all historical passages (context vectors/embeddings)\n",
        "- Generate embeddings for our questions (query vector/embedding)\n",
        "\n",
        "The retriever will create embeddings such that the questions and passages that hold the answers to our queries are close to one another in the vector space. We will use a SentenceTransformer model based on Microsoft's MPNet as our retriever. This model performs quite well for comparing the similarity between queries and documents. We can use Cosine Similarity to compute the similarity between query and context vectors generated by this model (Pinecone automatically does this for us)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "45dRrEZNPdXu"
      },
      "outputs": [],
      "source": [
        "# Already installed above\n",
        "# import torch\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# set device to GPU if available\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# load the retriever model from huggingface model hub\n",
        "# retriever = SentenceTransformer('flax-sentence-embeddings/all_datasets_v3_mpnet-base').to(device)\n",
        "# retriever"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Set device (GPU if available)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load lab retriever (768-dim, cosine-optimized)\n",
        "retriever = SentenceTransformer(\n",
        "    'flax-sentence-embeddings/all_datasets_v3_mpnet-base',\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Test\n",
        "test_texts = [\"What is machine learning?\", \"Machine learning definition\"]\n",
        "embeddings = retriever.encode(test_texts)\n",
        "print(f\"✅ Loaded retriever (shape: {embeddings.shape})\")  # (2, 768)\n",
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392,
          "referenced_widgets": [
            "fc60d56c160342b5bee8811b31d90b8c",
            "87039f5ef1dc4bea9efa91c08fd5ae8e",
            "60354558499a440cbc91629424de52f0",
            "1b931eca5f5145899f9713ba2826131b",
            "9ff56fc19aa24a13838c61d3e4481ab3",
            "dfef14b386c7471b971f5dc9978b543d",
            "b26675222777453789ff1ce53d7933e2",
            "ea56a7af12c14118bc357d9567438beb",
            "b1b2e49cb7e84b7bab348eb1fa2dac23",
            "bde81f5b92864343a738b5deece91e64",
            "1cde9b8f080445af902d150c65c0af03"
          ]
        },
        "id": "oKWN7gPXKsY_",
        "outputId": "0fbc2d60-9a01-42ab-cb3e-b9ac79efd443"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc60d56c160342b5bee8811b31d90b8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1mMPNetModel LOAD REPORT\u001b[0m from: flax-sentence-embeddings/all_datasets_v3_mpnet-base\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded retriever (shape: (2, 768))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'MPNetModel'})\n",
              "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YIzcMhWywOlD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f84bfd7e"
      },
      "source": [
        "#!pip install sympy==1.13.3"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jo5MN_GKPeDy"
      },
      "source": [
        "# Generate Embeddings and Upsert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj0NdB-kU9Yt"
      },
      "source": [
        "Next, we need to generate embeddings for the context passages. We will do this in batches to help us more quickly generate embeddings and upload them to the Pinecone index. When passing the documents to Pinecone, we need an id (a unique value), context embedding, and metadata for each document representing context passages in the dataset. The metadata is a dictionary containing data relevant to our embeddings, such as the article title, section title, passage text, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "f00e7425e9dc407182bab0a4aeda761d",
            "07d7c1b153944c5290a0dc2386eba212",
            "977ce7492ea343118db305f3b13dfa4b",
            "76db151d872f4246b33be96ab13dafc9",
            "ffd3825ddcc84169b20c8cd70437466b",
            "6a30811b2adf4b38aa5622cd0aea6403",
            "6cd4298bdbdb4448a161369251eb213b",
            "1fd0a96950074f8ab4432603332287f9",
            "a75c464719c34e8886c622248bb2d429",
            "c6f8045bccaf4260b375d1ec7a510a74",
            "27705d410479492894809403d6f6f33e"
          ]
        },
        "id": "4OqB7bBePia-",
        "outputId": "021f6471-722c-4618-e862-fb551bcf59ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/157 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f00e7425e9dc407182bab0a4aeda761d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'_response_info': {'raw_headers': {'connection': 'keep-alive',\n",
            "                                    'content-length': '189',\n",
            "                                    'content-type': 'application/json',\n",
            "                                    'date': 'Wed, 25 Feb 2026 21:49:26 GMT',\n",
            "                                    'grpc-status': '0',\n",
            "                                    'server': 'envoy',\n",
            "                                    'x-envoy-upstream-service-time': '40',\n",
            "                                    'x-pinecone-request-latency-ms': '40',\n",
            "                                    'x-pinecone-response-duration-ms': '41'}},\n",
            " 'dimension': 768,\n",
            " 'index_fullness': 0.0,\n",
            " 'memoryFullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {'__default__': {'vector_count': 40000}},\n",
            " 'storageFullness': 0.0,\n",
            " 'total_vector_count': 40000,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm\n",
        "import uuid\n",
        "\n",
        "# we will use batches of 64\n",
        "batch_size = 64\n",
        "\n",
        "for i in tqdm(range(0, len(df), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(df))\n",
        "    # extract batch\n",
        "    batch = df.iloc[i:i_end]\n",
        "    # generate embeddings for batch\n",
        "    emb = retriever.encode(batch['passage_text'].tolist()).tolist()\n",
        "\n",
        "    # Create Pinecone vectors with ID + metadata for this batch\n",
        "    pinecone_vectors_batch = []\n",
        "    for j, embedding in enumerate(emb):\n",
        "        pinecone_vectors_batch.append({\n",
        "            \"id\": str(uuid.uuid4()),  # Unique ID\n",
        "            \"values\": embedding,      # Embedding vector\n",
        "            \"metadata\": {\n",
        "                \"article_title\": batch['article_title'].iloc[j],\n",
        "                \"section_title\": batch['section_title'].iloc[j],\n",
        "                \"passage_text\": batch['passage_text'].iloc[j]\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # Upsert the current batch to Pinecone\n",
        "    index.upsert(vectors=pinecone_vectors_batch)\n",
        "\n",
        "# check that we have all vectors in index\n",
        "print(index.describe_index_stats())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFKPJ0WtPmAw"
      },
      "source": [
        "# Initialize Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RraVCG_hcv3"
      },
      "source": [
        "We will use ELI5 BART for the generator which is a Sequence-To-Sequence model trained using the ‘Explain Like I’m 5’ (ELI5) dataset. Sequence-To-Sequence models can take a text sequence as input and produce a different text sequence as output.\n",
        "\n",
        "The input to the ELI5 BART model is a single string which is a concatenation of the query and the relevant documents providing the context for the answer. The documents are separated by a special token &lt;P>, so the input string will look as follows:\n",
        "\n",
        ">question: What is a sonic boom? context: &lt;P> A sonic boom is a sound associated with shock waves created when an object travels through the air faster than the speed of sound. &lt;P> Sonic booms generate enormous amounts of sound energy, sounding similar to an explosion or a thunderclap to the human ear. &lt;P> Sonic booms due to large supersonic aircraft can be particularly loud and startling, tend to awaken people, and may cause minor damage to some structures. This led to prohibition of routine supersonic flight overland.\n",
        "\n",
        "More detail on how the ELI5 dataset was built is available [here](https://arxiv.org/abs/1907.09190) and how ELI5 BART model was trained is available [here](https://yjernite.github.io/lfqa.html).\n",
        "\n",
        "Let's initialize the BART model using transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77,
          "referenced_widgets": [
            "96d7b07cfef5431c9ed2cd159a056cbb",
            "41b18a2d968d408a8ba53b4d04dce646",
            "99ecfd18cbc84feda20cec59e5ae0333",
            "94f8a6f9484143bd84c260fc0687b1a7",
            "6fa4c0ecdfd24ff6a54558cb9bccf836",
            "c769514ef7ff4c5fa3f4b37f21eb2f7c",
            "a2427a0741e545a3a0c2be389385c357",
            "ee6b35db774540bf8761c38f644438ab",
            "a3712671633444db888f49901207b406",
            "ecc0e4dda5694703b17563c23bf98708",
            "b6847d0b64604ad9a9e005e642f9c33f"
          ]
        },
        "id": "76QyADZ0Pqki",
        "outputId": "55bbcf22-0f69-4278-ded9-2a8b3d1041a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/512 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96d7b07cfef5431c9ed2cd159a056cbb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "# load bart tokenizer and model from huggingface\n",
        "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
        "generator = BartForConditionalGeneration.from_pretrained('vblagoje/bart_lfqa').to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBr1GqvwkI3W"
      },
      "source": [
        "All the components of our abstract QA system are complete and ready to be queried. But first, let's write some helper functions to retrieve context passages from Pinecone index and to format the query in the way the generator expects the input."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def query_pinecone(query, top_k):\n",
        "    # generate embeddings for the query\n",
        "    xq = retriever.encode([query]).tolist()[0]\n",
        "    # search pinecone index for context passage with the answer\n",
        "    xc = index.query(\n",
        "        vector=xq,\n",
        "        top_k=top_k,\n",
        "        include_metadata=True\n",
        "    )\n",
        "    return xc"
      ],
      "metadata": {
        "id": "WG03lzST-Px7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_query(query, context):\n",
        "    # extract passage_text from Pinecone search result and add the <P> tag\n",
        "    context = [f\"<P> {m['metadata']['passage_text']}\" for m in context]\n",
        "    # concatinate all context passages\n",
        "    context = ' '.join(context)\n",
        "    # contcatinate the query and context passages\n",
        "    query = f\"question: {query} context: {context}\"\n",
        "    return query"
      ],
      "metadata": {
        "id": "RDtagMeHKgaJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA0f1Xyxq-Fp"
      },
      "source": [
        "Let's test the helper functions. We will query the Pinecone index function we created earlier with the `query_pinecone` to get context passages and pass them to the `format_query` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSm2nj11mR87",
        "outputId": "b2e58011-719b-4a67-bed0-754256f78cb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QueryResponse(matches=[{'id': '767ad4b9-a8cb-49d0-babc-b0294413689c',\n",
              " 'metadata': {'article_title': 'Electric power system',\n",
              "              'passage_text': 'Electric power system History In 1881, two '\n",
              "                              \"electricians built the world's first power \"\n",
              "                              'system at Godalming in England. It was powered '\n",
              "                              'by two waterwheels and produced an alternating '\n",
              "                              'current that in turn supplied seven Siemens arc '\n",
              "                              'lamps at 250 volts and 34 incandescent lamps at '\n",
              "                              '40 volts. However, supply to the lamps was '\n",
              "                              'intermittent and in 1882 Thomas Edison and his '\n",
              "                              'company, The Edison Electric Light Company, '\n",
              "                              'developed the first steam-powered electric '\n",
              "                              'power station on Pearl Street in New York City. '\n",
              "                              'The Pearl Street Station initially powered '\n",
              "                              'around 3,000 lamps for 59 customers. The power '\n",
              "                              'station generated direct current and',\n",
              "              'section_title': ''},\n",
              " 'score': 0.691844,\n",
              " 'values': []}], namespace='', usage={'read_units': 1}, _response_info={'raw_headers': {'date': 'Wed, 25 Feb 2026 21:49:29 GMT', 'content-type': 'application/json', 'content-length': '857', 'connection': 'keep-alive', 'x-pinecone-max-indexed-lsn': '628', 'x-pinecone-request-latency-ms': '116', 'x-envoy-upstream-service-time': '55', 'x-pinecone-response-duration-ms': '118', 'grpc-status': '0', 'server': 'envoy'}})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "query = \"when was the first electric power system built?\"\n",
        "result = query_pinecone(query, top_k=1)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6yoylQFO4joX"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPxVoo6am8ls",
        "outputId": "b6bce721-99e9-4f04-ecce-dca45e4adbf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('question: when was the first electric power system built? context: <P> '\n",
            " \"Electric power system History In 1881, two electricians built the world's \"\n",
            " 'first power system at Godalming in England. It was powered by two '\n",
            " 'waterwheels and produced an alternating current that in turn supplied seven '\n",
            " 'Siemens arc lamps at 250 volts and 34 incandescent lamps at 40 volts. '\n",
            " 'However, supply to the lamps was intermittent and in 1882 Thomas Edison and '\n",
            " 'his company, The Edison Electric Light Company, developed the first '\n",
            " 'steam-powered electric power station on Pearl Street in New York City. The '\n",
            " 'Pearl Street Station initially powered around 3,000 lamps for 59 customers. '\n",
            " 'The power station generated direct current and')\n"
          ]
        }
      ],
      "source": [
        "# format the query in the form generator expects the input\n",
        "query = format_query(query, result['matches'])\n",
        "pprint(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY8LSqk7rdPS"
      },
      "source": [
        "The output looks great. Now let's write a function to generate answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2fxIoNqeoEPD"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query):\n",
        "    # tokenize the query to get input_ids\n",
        "    inputs = tokenizer([query], max_length=1024, return_tensors=\"pt\").to(device)\n",
        "    # use generator to predict output ids\n",
        "    ids = generator.generate(inputs[\"input_ids\"], num_beams=2, min_length=20, max_length=40)\n",
        "    # use tokenizer to decode the output ids\n",
        "    answer = tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    return pprint(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYXFSBqSsZMx",
        "outputId": "6675b237-b8cb-4366-c7a4-0f55c0896eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The first electric power system was built in 1881 at Godalming in England. '\n",
            " 'It was powered by two waterwheels and produced alternating current that in '\n",
            " 'turn supplied seven Siemens arc lamps at')\n"
          ]
        }
      ],
      "source": [
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYWACzIotWQY"
      },
      "source": [
        "As we can see, the generator used the provided context to answer our question. Let's run some more queries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How was the first wireless message sent?\"\n",
        "context = query_pinecone(query, top_k=5)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCy5BiF1OURw",
        "outputId": "e30891d2-2f39-4b07-aee7-ed2ef33ae16a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The first wireless message was sent by a telegraph. The first telegraph was '\n",
            " 'built in the late 1800s, and it was used to send messages from London to New '\n",
            " 'York. The telegraph')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI2fTt_A5Ozf"
      },
      "source": [
        "To confirm that this answer is correct, we can check the contexts used to generate the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15WZSeZw3mNY",
        "outputId": "96434552-172e-4f7d-e7f8-92891d161f56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "audio distance records, and were heard as far west as Hawaii. They were also received in Paris, France, which marked the first transmission of speech across the Atlantic.\n",
            "With the entrance of the United States into World War I in April 1917 the federal government took over full control of the radio industry, and it became illegal for civilians to possess an operational radio receiver. However NAA continued to operate during the conflict. In addition to time signals and weather reports, it also broadcast news summaries received by troops on land and aboard ships in the Atlantic. Effective April 15, 1919\n",
            "---\n",
            "audio distance records, and were heard as far west as Hawaii. They were also received in Paris, France, which marked the first transmission of speech across the Atlantic.\n",
            "With the entrance of the United States into World War I in April 1917 the federal government took over full control of the radio industry, and it became illegal for civilians to possess an operational radio receiver. However NAA continued to operate during the conflict. In addition to time signals and weather reports, it also broadcast news summaries received by troops on land and aboard ships in the Atlantic. Effective April 15, 1919\n",
            "---\n",
            "audio distance records, and were heard as far west as Hawaii. They were also received in Paris, France, which marked the first transmission of speech across the Atlantic.\n",
            "With the entrance of the United States into World War I in April 1917 the federal government took over full control of the radio industry, and it became illegal for civilians to possess an operational radio receiver. However NAA continued to operate during the conflict. In addition to time signals and weather reports, it also broadcast news summaries received by troops on land and aboard ships in the Atlantic. Effective April 15, 1919\n",
            "---\n",
            "audio distance records, and were heard as far west as Hawaii. They were also received in Paris, France, which marked the first transmission of speech across the Atlantic.\n",
            "With the entrance of the United States into World War I in April 1917 the federal government took over full control of the radio industry, and it became illegal for civilians to possess an operational radio receiver. However NAA continued to operate during the conflict. In addition to time signals and weather reports, it also broadcast news summaries received by troops on land and aboard ships in the Atlantic. Effective April 15, 1919\n",
            "---\n",
            "radio operators, interested in a practical benefit from their hobby, and jewelers, who previously had been reliant on time services transmitted over telegraph wires, which had a reputation for being both expensive and of questionable reliability, especially compared to the free and very accurate NAA transmissions.\n",
            "NAA's original transmitters were only capable of producing the dots-and-dashes of Morse code. The later development of vacuum tube transmitters made audio transmissions practical, and in 1915 the American Telephone and Telegraph Company (AT&T) received permission from the Navy to conduct a series of tests at the NAA facility. These experimental transmissions set impressive new\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for doc in context[\"matches\"]:\n",
        "    print(doc[\"metadata\"][\"passage_text\"], end='\\n---\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH-K7WHR9z8m"
      },
      "source": [
        "In this case, the answer looks correct. If we ask a question and no relevant contexts are retrieved, the generator will typically return nonsensical or false answers, like with this question about COVID-19:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1naD6pRlmWd",
        "outputId": "b94bf8b5-795e-4dac-b44a-8874f6914ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('COVID-19 is a strain of the coronaviruses. The coronaviruses are a group of '\n",
            " 'viruses that infect humans. The coronaviruses are a group of viruses that')\n"
          ]
        }
      ],
      "source": [
        "query = \"where did COVID-19 originate?\"\n",
        "context = query_pinecone(query, top_k=5)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3gX5xQY-jKJ",
        "outputId": "b7580aa7-527a-4f68-8971-ce622c44af0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man killed and twenty-nine died of disease.\n",
            "---\n",
            "man killed and twenty-nine died of disease.\n",
            "---\n",
            "man killed and twenty-nine died of disease.\n",
            "---\n",
            "man killed and twenty-nine died of disease.\n",
            "---\n",
            "diseases when they occupy at certain times of the year natural habitat of a certain pathogen (plague, tularemia, leptospirosis, arboviruses, tick-borne relapsing fever. The WHO Expert Committee on Zoonoses listed over 100 such diseases. About natural focality of the diseases is known elsewhere. History Historically, Sanitary epidemiological reconnaissance implied collection and transfer of all data available on sanitary and epidemiological situation of the area of possible deployment and action of armed forces, the same data for the neighbouring and enemy armed forces. The aim for the reconnaissance was to clear up the reasons of the specific disease origin—sources of the\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for doc in context[\"matches\"]:\n",
        "    print(doc[\"metadata\"][\"passage_text\"], end='\\n---\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCUqB_MrAABI"
      },
      "source": [
        "Let’s finish with a final few questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_oWypShW_rk",
        "outputId": "ec1b6992-cea2-4a75-91ea-2a8b88929f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The War of Currents was a rivalry between Thomas Edison and George '\n",
            " \"Westinghouse's companies over which form of transmission (direct or \"\n",
            " 'alternating current) was superior, a series of events known as the')\n"
          ]
        }
      ],
      "source": [
        "query = \"what was the war of currents?\"\n",
        "context = query_pinecone(query, top_k=5)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ1-OsmT0duI",
        "outputId": "891bac8d-1432-43e8-e283-c60a87b615f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The first person to walk on the moon was Giovanni Cassini. He walked on the '\n",
            " 'moon in 1969.')\n"
          ]
        }
      ],
      "source": [
        "query = \"who was the first person on the moon?\"\n",
        "context = query_pinecone(query, top_k=3)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU6DH-ah1g1t",
        "outputId": "9c2d7506-aa27-4cc5-d6cc-7de847fcb18e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The Space Shuttle was the most expensive project in the history of NASA. It '\n",
            " 'cost about $10 billion to build.')\n"
          ]
        }
      ],
      "source": [
        "query = \"what was NASAs most expensive project?\"\n",
        "context = query_pinecone(query, top_k=3)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-cQPSkG9cFY"
      },
      "source": [
        "As we can see, the model can generate some decent answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyj_vCBko6tm"
      },
      "source": [
        "#### Add a few more questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zSrF9_4Do6tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1807898d-d570-4899-cf09-e3f3db7324ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"I'm not sure if this is the right subreddit to ask this question, but I'll \"\n",
            " \"try to answer it anyway. I'm not a historian, but I do have a degree in \"\n",
            " 'computer science')\n"
          ]
        }
      ],
      "source": [
        "query = \"Who invented television?\"\n",
        "context = query_pinecone(query, top_k=10)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who designed the Sydney Opera house?\"\n",
        "context = query_pinecone(query, top_k=10)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZQB4_4p36H8",
        "outputId": "875cfa72-1614-4cdd-a756-48e4eded9351"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The Sydney Opera House was designed by Samuel Sloan, of Philadelphia, and '\n",
            " 'his assistant, Aldophus Gustavus Bauer, were chosen as architects. Sloan '\n",
            " 'arrived in Raleigh with his designs for the elaborate')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"How is Joghurt produced?\"\n",
        "context = query_pinecone(query, top_k=10)\n",
        "query = format_query(query, context[\"matches\"])\n",
        "generate_answer(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEYwqN5E36uM",
        "outputId": "6b70e8a9-cbf9-4603-e1fb-bdb08a293d00"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"I'm not sure if this is what you're looking for, but I can tell you that \"\n",
            " 'yogurt is made by fermenting milk. The milk is then heated to a temperature '\n",
            " 'where the lactose')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84165d4c9b0d4870ab75f94fdd2988b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a45906e001b14c838c79e09388f4b354",
              "IPY_MODEL_797f94464acc469ea68c9d3522554986",
              "IPY_MODEL_deee5e26f38c459d8dcf26169d5fa133"
            ],
            "layout": "IPY_MODEL_55c9bee27d1b4581ab39016825ce7445"
          }
        },
        "a45906e001b14c838c79e09388f4b354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24ac69baa134755a70a18084bf97f10",
            "placeholder": "​",
            "style": "IPY_MODEL_bce6c37c882f41fbb557f4244b33f0cf",
            "value": "100%"
          }
        },
        "797f94464acc469ea68c9d3522554986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d48fb4902c7a42b08519b856aa12acf4",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a2d0e72ddbb417f866ad40017f35953",
            "value": 10000
          }
        },
        "deee5e26f38c459d8dcf26169d5fa133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec08e63ee75c4fd99e110ab7df43425b",
            "placeholder": "​",
            "style": "IPY_MODEL_5f5bc42fe47f4dc782f3a26f42f19c53",
            "value": " 10000/10000 [01:54&lt;00:00, 134.94it/s]"
          }
        },
        "55c9bee27d1b4581ab39016825ce7445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24ac69baa134755a70a18084bf97f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce6c37c882f41fbb557f4244b33f0cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d48fb4902c7a42b08519b856aa12acf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a2d0e72ddbb417f866ad40017f35953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec08e63ee75c4fd99e110ab7df43425b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f5bc42fe47f4dc782f3a26f42f19c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc60d56c160342b5bee8811b31d90b8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87039f5ef1dc4bea9efa91c08fd5ae8e",
              "IPY_MODEL_60354558499a440cbc91629424de52f0",
              "IPY_MODEL_1b931eca5f5145899f9713ba2826131b"
            ],
            "layout": "IPY_MODEL_9ff56fc19aa24a13838c61d3e4481ab3"
          }
        },
        "87039f5ef1dc4bea9efa91c08fd5ae8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfef14b386c7471b971f5dc9978b543d",
            "placeholder": "​",
            "style": "IPY_MODEL_b26675222777453789ff1ce53d7933e2",
            "value": "Loading weights: 100%"
          }
        },
        "60354558499a440cbc91629424de52f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea56a7af12c14118bc357d9567438beb",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1b2e49cb7e84b7bab348eb1fa2dac23",
            "value": 199
          }
        },
        "1b931eca5f5145899f9713ba2826131b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bde81f5b92864343a738b5deece91e64",
            "placeholder": "​",
            "style": "IPY_MODEL_1cde9b8f080445af902d150c65c0af03",
            "value": " 199/199 [00:00&lt;00:00, 458.01it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "9ff56fc19aa24a13838c61d3e4481ab3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfef14b386c7471b971f5dc9978b543d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b26675222777453789ff1ce53d7933e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea56a7af12c14118bc357d9567438beb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b2e49cb7e84b7bab348eb1fa2dac23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bde81f5b92864343a738b5deece91e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cde9b8f080445af902d150c65c0af03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f00e7425e9dc407182bab0a4aeda761d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07d7c1b153944c5290a0dc2386eba212",
              "IPY_MODEL_977ce7492ea343118db305f3b13dfa4b",
              "IPY_MODEL_76db151d872f4246b33be96ab13dafc9"
            ],
            "layout": "IPY_MODEL_ffd3825ddcc84169b20c8cd70437466b"
          }
        },
        "07d7c1b153944c5290a0dc2386eba212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a30811b2adf4b38aa5622cd0aea6403",
            "placeholder": "​",
            "style": "IPY_MODEL_6cd4298bdbdb4448a161369251eb213b",
            "value": "100%"
          }
        },
        "977ce7492ea343118db305f3b13dfa4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fd0a96950074f8ab4432603332287f9",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a75c464719c34e8886c622248bb2d429",
            "value": 157
          }
        },
        "76db151d872f4246b33be96ab13dafc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6f8045bccaf4260b375d1ec7a510a74",
            "placeholder": "​",
            "style": "IPY_MODEL_27705d410479492894809403d6f6f33e",
            "value": " 157/157 [02:54&lt;00:00,  1.13it/s]"
          }
        },
        "ffd3825ddcc84169b20c8cd70437466b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a30811b2adf4b38aa5622cd0aea6403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cd4298bdbdb4448a161369251eb213b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fd0a96950074f8ab4432603332287f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a75c464719c34e8886c622248bb2d429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6f8045bccaf4260b375d1ec7a510a74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27705d410479492894809403d6f6f33e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d7b07cfef5431c9ed2cd159a056cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41b18a2d968d408a8ba53b4d04dce646",
              "IPY_MODEL_99ecfd18cbc84feda20cec59e5ae0333",
              "IPY_MODEL_94f8a6f9484143bd84c260fc0687b1a7"
            ],
            "layout": "IPY_MODEL_6fa4c0ecdfd24ff6a54558cb9bccf836"
          }
        },
        "41b18a2d968d408a8ba53b4d04dce646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c769514ef7ff4c5fa3f4b37f21eb2f7c",
            "placeholder": "​",
            "style": "IPY_MODEL_a2427a0741e545a3a0c2be389385c357",
            "value": "Loading weights: 100%"
          }
        },
        "99ecfd18cbc84feda20cec59e5ae0333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee6b35db774540bf8761c38f644438ab",
            "max": 512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3712671633444db888f49901207b406",
            "value": 512
          }
        },
        "94f8a6f9484143bd84c260fc0687b1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecc0e4dda5694703b17563c23bf98708",
            "placeholder": "​",
            "style": "IPY_MODEL_b6847d0b64604ad9a9e005e642f9c33f",
            "value": " 512/512 [00:00&lt;00:00, 707.85it/s, Materializing param=model.shared.weight]"
          }
        },
        "6fa4c0ecdfd24ff6a54558cb9bccf836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c769514ef7ff4c5fa3f4b37f21eb2f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2427a0741e545a3a0c2be389385c357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee6b35db774540bf8761c38f644438ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3712671633444db888f49901207b406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecc0e4dda5694703b17563c23bf98708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6847d0b64604ad9a9e005e642f9c33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}